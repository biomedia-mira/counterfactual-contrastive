{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE evaluation of features on EMBED dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(\"/vol/biomedic3/mb121/causal-contrastive\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from classification.classification_module import ClassificationModule\n",
    "from hydra import compose, initialize\n",
    "from data_handling.mammo import preprocess_breast\n",
    "from pathlib import Path\n",
    "from data_handling.mammo import EmbedDataModule, modelname_map\n",
    "from data_handling.xray import PadChestDataModule\n",
    "\n",
    "rev_model_map = {v: k for k, v in modelname_map.items()}\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, class_names=None, normalize=None):\n",
    "    \"\"\"\n",
    "    Plot a confusion matrix using seaborn's heatmap.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    conf_matrix : numpy.ndarray\n",
    "        The confusion matrix to plot\n",
    "    class_names : list, optional\n",
    "        List of class names for axis labels\n",
    "    normalize : str, optional\n",
    "        Indicates if the confusion matrix is normalized\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5, 5))\n",
    "\n",
    "    # If class names not provided, use numeric indices\n",
    "    if class_names is None:\n",
    "        class_names = [str(i) for i in range(len(conf_matrix))]\n",
    "\n",
    "    # Format annotation based on normalization\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "\n",
    "    # Create a heatmap\n",
    "    sns.heatmap(\n",
    "        conf_matrix,\n",
    "        annot=True,\n",
    "        fmt=fmt,\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        vmin=0,\n",
    "        vmax=1 if normalize else None,\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "\n",
    "    title = \"Average Confusion Matrix\"\n",
    "    if normalize == \"true\":\n",
    "        title += \" (Normalized by Row)\"\n",
    "    elif normalize == \"pred\":\n",
    "        title += \" (Normalized by Column)\"\n",
    "    elif normalize == \"all\":\n",
    "        title += \" (Normalized by Total)\"\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"../configs\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"config.yaml\",\n",
    "        overrides=[\"experiment=base_density\", \"data.cache=False\"],\n",
    "    )\n",
    "    print(cfg)\n",
    "    data_module = EmbedDataModule(config=cfg)\n",
    "test_loader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_for_embeddings = {\n",
    "    \"SimCLR\": \"byatk1eo\",\n",
    "    \"SimCLR+\": \"jv9hzx89\",\n",
    "    \"CF-SimCLR\": \"kywspwfs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.helper_functions import run_get_embeddings\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "results = {}\n",
    "\n",
    "for run_name, run_id in model_dict_for_embeddings.items():\n",
    "    if run_id != \"\":\n",
    "        print(run_name)\n",
    "        model_to_evaluate = f\"../outputs/run_{run_id}/epoch=449.ckpt\"\n",
    "        classification_model = ClassificationModule.load_from_checkpoint(\n",
    "            model_to_evaluate, map_location=\"cuda\", config=cfg, strict=False\n",
    "        ).model.eval()\n",
    "        classification_model.cuda()\n",
    "        # ID evaluation\n",
    "        inference_results = run_get_embeddings(\n",
    "            test_loader, classification_model, max_batch=2063\n",
    "        )\n",
    "        inference_results[\"scanners\"] = np.argmax(inference_results[\"scanners\"], 1)\n",
    "        results[run_name] = inference_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tsne = {}\n",
    "all_scanners_name = {}\n",
    "\n",
    "for i, (run_name, inference_results) in enumerate(results.items()):\n",
    "    scanners = inference_results[\"scanners\"]\n",
    "    tsne = TSNE(n_jobs=6, perplexity=30, random_state=33)\n",
    "    x2d = tsne.fit_transform(inference_results[\"feats\"])\n",
    "    scanners_plot = [rev_model_map[s] for s in scanners]\n",
    "    all_tsne[run_name] = x2d\n",
    "    all_scanners_name[run_name] = scanners_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {\n",
    "    s: sns.color_palette(\"colorblind\", 7)[i]\n",
    "    for s, i in zip(np.unique(list(rev_model_map.values())), [1, 3, 0, 4, 5, 5])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"font.family\"] = \"serif\"\n",
    "f, ax = plt.subplots(1, len(results.keys()), figsize=(20, 4), facecolor=\"none\")\n",
    "\n",
    "coords_anomaly = {\n",
    "    \"SimCLR\": (-100, -48, 28, 28),\n",
    "    \"SimCLR+\": (-94, -75, 27, 34),\n",
    "    \"CF-SimCLR\": (-103, -57, 24, 33),\n",
    "}\n",
    "\n",
    "for i, run_name in enumerate(all_tsne.keys()):\n",
    "    scanners = inference_results[\"scanners\"]\n",
    "    x2d = all_tsne[run_name]\n",
    "    idx = np.random.permutation(x2d.shape[0])\n",
    "    scanners_plot = np.asarray(all_scanners_name[run_name])[idx]\n",
    "    sns.scatterplot(\n",
    "        x=x2d[idx, 0],\n",
    "        y=x2d[idx, 1],\n",
    "        hue=scanners_plot,\n",
    "        ax=ax[i],\n",
    "        palette=palette,\n",
    "        legend=i == 0,\n",
    "        alpha=1.0,\n",
    "        s=30,\n",
    "    )\n",
    "    ax[i].set_xlabel(\"\")\n",
    "    ax[i].set_ylabel(\"\")\n",
    "    ax[i].set_title(run_name, fontsize=18)\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    if run_name in coords_anomaly.keys():\n",
    "        left, bottom, width, height = coords_anomaly[run_name]\n",
    "        rect = mpatches.Rectangle(\n",
    "            (left, bottom),\n",
    "            width,\n",
    "            height,\n",
    "            fill=False,\n",
    "            color=\"black\",\n",
    "            linewidth=2,\n",
    "            label=\"Cluster of breast implants\",\n",
    "        )\n",
    "        ax[i].add_patch(rect)\n",
    "        outliers = np.where(\n",
    "            (left < x2d[:, 0])\n",
    "            & (x2d[:, 0] < left + width)\n",
    "            & (bottom < x2d[:, 1])\n",
    "            & (x2d[:, 1] < bottom + height)\n",
    "        )[0]\n",
    "        shorts_path = inference_results[\"paths\"][outliers]\n",
    "        img_dir = \"/vol/biomedic3/data/EMBED\"\n",
    "        img = preprocess_breast(\n",
    "            Path(img_dir) / \"images/png/1024x768\" / shorts_path[33], (256, 192)\n",
    "        )[0]\n",
    "        im = OffsetImage(img, zoom=0.15, cmap=\"gray\")\n",
    "        ab = AnnotationBbox(\n",
    "            im,\n",
    "            xy=(left + width / 2, bottom),\n",
    "            xybox=(left - 6, bottom - 33),\n",
    "            pad=0,\n",
    "            arrowprops={\n",
    "                \"arrowstyle\": \"simple\",\n",
    "                \"facecolor\": \"black\",\n",
    "                \"mutation_scale\": 3,\n",
    "            },\n",
    "        )\n",
    "        ax[i].add_artist(ab)\n",
    "\n",
    "ax[0].legend(\n",
    "    loc=\"center\", bbox_to_anchor=(1.7, -0.18), ncol=6, fontsize=12.35, markerscale=2\n",
    ")\n",
    "\n",
    "ax[0].set_xlim((-118, 110))\n",
    "ax[0].set_ylim((-102, 110))\n",
    "ax[1].set_xlim((-112, 110))\n",
    "ax[1].set_ylim((-132, 110))\n",
    "ax[2].set_xlim((-122, 108))\n",
    "ax[2].set_ylim((-111.5, 105))\n",
    "\n",
    "plt.savefig(\"figures/embeddings_tsne.png\", bbox_inches=\"tight\", dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting scanner from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "for name, inference_results in results.items():\n",
    "    # Initialize stratified k-fold\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "    # Lists to store results\n",
    "    conf_matrices = []\n",
    "    accuracies = []\n",
    "\n",
    "    X = inference_results[\"feats\"]\n",
    "    y = inference_results[\"scanners\"]\n",
    "    idx = np.concatenate(\n",
    "        [\n",
    "            np.random.choice(\n",
    "                np.where(inference_results[\"scanners\"] == i)[0],\n",
    "                min(1000, np.sum(inference_results[\"scanners\"] == i)),\n",
    "                replace=False,\n",
    "            )\n",
    "            for i in range(5)\n",
    "        ]\n",
    "    )\n",
    "    print(np.bincount(y[idx]))\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "    # Perform cross-validation\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        # Split data\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        classifier = Pipeline([(\"pca\", PCA(16)), (\"rf\", LogisticRegression())])\n",
    "\n",
    "        # Train model\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred, normalize=\"true\")\n",
    "        conf_matrices.append(cm)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = np.mean(np.diag(cm))\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Calculate average confusion matrix\n",
    "    avg_conf_matrix = np.mean(conf_matrices, axis=0)\n",
    "    \n",
    "    print(name)\n",
    "    print(f\"\\nAverage Accuracy: {np.mean(accuracies):.4f} (Â±{np.std(accuracies):.4f})\")\n",
    "    plot_confusion_matrix(avg_conf_matrix, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
